{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk30NGu8i_Nc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip /content/drive/My\\ Drive/hist/histopathologic-cancer-detection.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxuxP3ijaB80",
        "colab_type": "text"
      },
      "source": [
        "We are unzipping our dataset into colab using commandline tool called Unzip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRK67zlRiuTO",
        "colab_type": "code",
        "colab": {},
        "cellView": "code"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "from skimage.io import imread \n",
        "import os\n",
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGOJRqSqaRA2",
        "colab_type": "text"
      },
      "source": [
        "**Pandas** library is used to read and work with .CSV fiels\n",
        "**os** and **shutil** library is used to work with directories and copying of files\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34XraJAai_7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir /content/train/0\n",
        "!mkdir /content/train/1\n",
        "import shutil as sh #move files\n",
        "import pandas as pd #read csv\n",
        "df_train=pd.read_csv(\"/content/train_labels.csv\")\n",
        "for index, row in df_train.iterrows():\n",
        "    if row['label']==0:\n",
        "        a=str(row['id'])+'.tif'\n",
        "        sh.move(('/content/train/'+ a),'/content/train/0/')\n",
        "    elif row['label']==1:\n",
        "        a=str(row['id'])+'.tif'\n",
        "        sh.move(('/content/train/'+ a),'/content/train/1/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vr5j-p1CbJ4m",
        "colab_type": "text"
      },
      "source": [
        "We are creating two directories called 0 & 1 \n",
        "then we will read data from .csv file which contains image id and its label\n",
        "according to the label we will move the file from train directory to its respective label directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkPuIUtEjHPL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d491479e-316e-4dd0-9c77-41c621d545d4"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from keras import layers\n",
        "import tensorflow\n",
        "from keras.layers import Flatten, Dense, Input, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import sequence, image\n",
        "from keras import layers\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import Callback\n",
        "from keras.models import Sequential\n",
        "import keras\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-65_YZdTb0hI",
        "colab_type": "text"
      },
      "source": [
        "Here we are specifying the version of Tensorflow to 1.x\n",
        "tensorflow 1.x is used because Keras is not compatible with the 2.x version of tensorflow\n",
        "all other modules from keras are imported to build a model\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlA8Uyr0jSFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_SIZE = 96\n",
        "\n",
        "batch_size=512"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYNbQA86cUKm",
        "colab_type": "text"
      },
      "source": [
        "Default Image size is 96 \n",
        "Batch size is set to 512"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0_2qd3ojT60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                             horizontal_flip=True,\n",
        "                                             vertical_flip=True,\n",
        "                                             rotation_range=90,\n",
        "                                             zoom_range=0.2, \n",
        "                                             width_shift_range=0.1,\n",
        "                                             height_shift_range=0.1,\n",
        "                                             shear_range=0.05,\n",
        "                                             channel_shift_range=0.1,\n",
        "                                             validation_split=0.2\n",
        "                             )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPLH5eePcbf2",
        "colab_type": "text"
      },
      "source": [
        "object of Image datagenerator is created and it is  used to preprocess images before passing it to neural network model\n",
        "And the preprocessing parameters were defined \n",
        "For more info : https://keras.io/api/preprocessing/image/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP4bROxEjVwo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f3d9376d-b8b2-4adf-d9fb-dfdff51f25c6"
      },
      "source": [
        "train_generator = datagen.flow_from_directory(\n",
        "        '/content/train',  # this is the target directory\n",
        "        color_mode=\"rgb\",\n",
        "        target_size=(96,96),  # all images will be resized to 150x150\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        class_mode='binary',\n",
        "        seed=45,\n",
        "        classes=['0','1'],\n",
        "\t      subset=\"training\"       \n",
        "       )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 176021 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9QClSGgdECT",
        "colab_type": "text"
      },
      "source": [
        "Train generator is created. This is an iterator which is used to iterate over a directory of images\n",
        "Random seed is set to 45\n",
        "color mode is set to rgb\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Rc_1FUXjXoS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "6ade33d2-3b25-4d78-ec60-5da4c93e6b21"
      },
      "source": [
        "validation_generator = datagen.flow_from_directory(\n",
        "        '/content/train',  # this is the target directory\n",
        "        color_mode=\"rgb\",\n",
        "        target_size=(96,96),  # all images will be resized to 150x150\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        class_mode='binary',\n",
        "        classes=['0','1'],\n",
        "        subset=\"validation\"       \n",
        "       )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 44004 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuvVQB2ndX8j",
        "colab_type": "text"
      },
      "source": [
        "validation generator is created. This is an iterator which is used to iterate over a directory of images\n",
        "Random seed is set to 45\n",
        "color mode is set to rgb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e-ceqHTjZzx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "d53b8f0e-f194-4ede-958b-df2e6cee47eb"
      },
      "source": [
        "model= keras.applications.vgg16.VGG16(include_top=False, weights='imagenet',input_shape=(96,96,3),pooling='avg')\n",
        "x = model.output\n",
        "\n",
        "\n",
        "\n",
        "x = Dense(32)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)          \n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "\n",
        "x = Dense(16)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)          \n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "\n",
        "x = Dense(8)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)          \n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "x = Dense(4)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)          \n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model= Model(input = model.input, output = predictions)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 2s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4aYHrofde0x",
        "colab_type": "text"
      },
      "source": [
        "VGG16 model is imported and used here\n",
        "Pretrained weights are Imagenet \n",
        "Avg pooling layers are used\n",
        "Dense/Fully connected network is defined\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK1dAY8skjBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath=\"vgg16_2_model.hdf5\" # checkpoint\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_binary_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "adam = keras.optimizers.Adam(lr=0.0001)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n_b_jMyd9t_",
        "colab_type": "text"
      },
      "source": [
        "here a checkpoint is defined which will save the model after every epoch only if the accuracy is highest "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H3CWHPjkmaS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "3f2ed7c8-45f7-4405-ce07-ec3087a4ec6d"
      },
      "source": [
        "model.compile(\n",
        "          optimizer=adam,\n",
        "          loss='binary_crossentropy',\n",
        "          metrics=['binary_accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knIjzQ7FerwA",
        "colab_type": "text"
      },
      "source": [
        "The model is compiled here with the adam optimizer and binary cross entropy as loss function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82mS7yNhkx-d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3db83a99-5c6a-4cf9-a46e-07fc69f38f03"
      },
      "source": [
        "final_model=model.fit_generator(train_generator,\n",
        "                    steps_per_epoch=train_generator.samples //batch_size ,\n",
        "                    validation_data = validation_generator,\n",
        "                    validation_steps=validation_generator.samples // batch_size,\n",
        "                    epochs=50,\n",
        "                    verbose=1,\n",
        "                    shuffle=True,\n",
        "                    callbacks=[checkpoint],\n",
        "                    max_queue_size=60, \n",
        "                    workers=5, \n",
        "                    use_multiprocessing=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/50\n",
            "343/343 [==============================] - 604s 2s/step - loss: 0.5516 - binary_accuracy: 0.7261 - val_loss: 0.4716 - val_binary_accuracy: 0.8193\n",
            "\n",
            "Epoch 00001: val_binary_accuracy improved from -inf to 0.81935, saving model to vgg16_2_model.hdf5\n",
            "Epoch 2/50\n",
            "343/343 [==============================] - 582s 2s/step - loss: 0.4705 - binary_accuracy: 0.7985 - val_loss: 0.3909 - val_binary_accuracy: 0.8610\n",
            "\n",
            "Epoch 00002: val_binary_accuracy improved from 0.81935 to 0.86101, saving model to vgg16_2_model.hdf5\n",
            "Epoch 3/50\n",
            "343/343 [==============================] - 578s 2s/step - loss: 0.4324 - binary_accuracy: 0.8263 - val_loss: 0.3256 - val_binary_accuracy: 0.9195\n",
            "\n",
            "Epoch 00003: val_binary_accuracy improved from 0.86101 to 0.91953, saving model to vgg16_2_model.hdf5\n",
            "Epoch 4/50\n",
            "343/343 [==============================] - 583s 2s/step - loss: 0.4001 - binary_accuracy: 0.8452 - val_loss: 0.3186 - val_binary_accuracy: 0.8895\n",
            "\n",
            "Epoch 00004: val_binary_accuracy did not improve from 0.91953\n",
            "Epoch 5/50\n",
            "343/343 [==============================] - 588s 2s/step - loss: 0.3703 - binary_accuracy: 0.8615 - val_loss: 0.3608 - val_binary_accuracy: 0.8883\n",
            "\n",
            "Epoch 00005: val_binary_accuracy did not improve from 0.91953\n",
            "Epoch 6/50\n",
            "343/343 [==============================] - 585s 2s/step - loss: 0.3476 - binary_accuracy: 0.8719 - val_loss: 0.2786 - val_binary_accuracy: 0.9049\n",
            "\n",
            "Epoch 00006: val_binary_accuracy did not improve from 0.91953\n",
            "Epoch 7/50\n",
            "343/343 [==============================] - 589s 2s/step - loss: 0.3242 - binary_accuracy: 0.8835 - val_loss: 0.2243 - val_binary_accuracy: 0.9405\n",
            "\n",
            "Epoch 00007: val_binary_accuracy improved from 0.91953 to 0.94047, saving model to vgg16_2_model.hdf5\n",
            "Epoch 8/50\n",
            "343/343 [==============================] - 591s 2s/step - loss: 0.3060 - binary_accuracy: 0.8903 - val_loss: 0.2056 - val_binary_accuracy: 0.9396\n",
            "\n",
            "Epoch 00008: val_binary_accuracy did not improve from 0.94047\n",
            "Epoch 9/50\n",
            "343/343 [==============================] - 595s 2s/step - loss: 0.2885 - binary_accuracy: 0.8965 - val_loss: 0.1933 - val_binary_accuracy: 0.9387\n",
            "\n",
            "Epoch 00009: val_binary_accuracy did not improve from 0.94047\n",
            "Epoch 10/50\n",
            "343/343 [==============================] - 597s 2s/step - loss: 0.2737 - binary_accuracy: 0.9040 - val_loss: 0.2180 - val_binary_accuracy: 0.9312\n",
            "\n",
            "Epoch 00010: val_binary_accuracy did not improve from 0.94047\n",
            "Epoch 11/50\n",
            "343/343 [==============================] - 608s 2s/step - loss: 0.2613 - binary_accuracy: 0.9080 - val_loss: 0.1814 - val_binary_accuracy: 0.9404\n",
            "\n",
            "Epoch 00011: val_binary_accuracy did not improve from 0.94047\n",
            "Epoch 12/50\n",
            "343/343 [==============================] - 601s 2s/step - loss: 0.2498 - binary_accuracy: 0.9113 - val_loss: 0.1984 - val_binary_accuracy: 0.9263\n",
            "\n",
            "Epoch 00012: val_binary_accuracy did not improve from 0.94047\n",
            "Epoch 13/50\n",
            "343/343 [==============================] - 589s 2s/step - loss: 0.2410 - binary_accuracy: 0.9139 - val_loss: 0.1874 - val_binary_accuracy: 0.9364\n",
            "\n",
            "Epoch 00013: val_binary_accuracy did not improve from 0.94047\n",
            "Epoch 14/50\n",
            "343/343 [==============================] - 582s 2s/step - loss: 0.2332 - binary_accuracy: 0.9158 - val_loss: 0.1734 - val_binary_accuracy: 0.9391\n",
            "\n",
            "Epoch 00014: val_binary_accuracy did not improve from 0.94047\n",
            "Epoch 15/50\n",
            "343/343 [==============================] - 583s 2s/step - loss: 0.2263 - binary_accuracy: 0.9173 - val_loss: 0.1466 - val_binary_accuracy: 0.9515\n",
            "\n",
            "Epoch 00015: val_binary_accuracy improved from 0.94047 to 0.95151, saving model to vgg16_2_model.hdf5\n",
            "Epoch 16/50\n",
            "343/343 [==============================] - 582s 2s/step - loss: 0.2202 - binary_accuracy: 0.9186 - val_loss: 0.1423 - val_binary_accuracy: 0.9520\n",
            "\n",
            "Epoch 00016: val_binary_accuracy improved from 0.95151 to 0.95197, saving model to vgg16_2_model.hdf5\n",
            "Epoch 17/50\n",
            "343/343 [==============================] - 588s 2s/step - loss: 0.2126 - binary_accuracy: 0.9214 - val_loss: 0.1341 - val_binary_accuracy: 0.9552\n",
            "\n",
            "Epoch 00017: val_binary_accuracy improved from 0.95197 to 0.95523, saving model to vgg16_2_model.hdf5\n",
            "Epoch 18/50\n",
            "343/343 [==============================] - 586s 2s/step - loss: 0.2072 - binary_accuracy: 0.9225 - val_loss: 0.1309 - val_binary_accuracy: 0.9564\n",
            "\n",
            "Epoch 00018: val_binary_accuracy improved from 0.95523 to 0.95643, saving model to vgg16_2_model.hdf5\n",
            "Epoch 19/50\n",
            "175/343 [==============>...............] - ETA: 3:53 - loss: 0.2016 - binary_accuracy: 0.9249"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Process ForkPoolWorker-181:\n",
            "Process ForkPoolWorker-182:\n",
            "Process ForkPoolWorker-176:\n",
            "Process ForkPoolWorker-179:\n",
            "Process ForkPoolWorker-177:\n",
            "Process ForkPoolWorker-178:\n",
            "Process ForkPoolWorker-180:\n",
            "Process ForkPoolWorker-185:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 133, in worker\n",
            "    completed += 1\n",
            "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
            "    task = get()\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\", line 406, in get_index\n",
            "    return _SHARED_SEQUENCES[uid][i]\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
            "    res = self._reader.recv_bytes()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n",
            "    return self._get_batches_of_transformed_samples(index_array)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\", line 406, in get_index\n",
            "    return _SHARED_SEQUENCES[uid][i]\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
            "    buf = self._recv_bytes(maxlength)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n",
            "    interpolation=self.interpolation)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n",
            "    return self._get_batches_of_transformed_samples(index_array)\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n",
            "    interpolation=self.interpolation)\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\", line 110, in load_img\n",
            "    img = pil_image.open(path)\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
            "    buf = self._recv(4)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 2818, in open\n",
            "    prefix = fp.read(16)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\", line 110, in load_img\n",
            "    img = pil_image.open(path)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
            "    chunk = read(handle, remaining)\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 2818, in open\n",
            "    prefix = fp.read(16)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1a07e4342dde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                     use_multiprocessing=True)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    601\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwItvPz9e4bt",
        "colab_type": "text"
      },
      "source": [
        "using model.fit_generator the model was trained \n",
        "for more info https://keras.io/api/models/model_training_apis/#fit-method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5u3cY57lABx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/vgg16_2_model.hdf5 /content/drive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqpiSOPce2f2",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqAJKS-URaMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}